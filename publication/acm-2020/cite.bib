@inproceedings{10.1145/3377325.3377533,
author = {Mittal, Paritosh and Aggarwal, Kunal and Sahu, Pragya Paramita and Vatsalya, Vishal and Mitra, Soumyajit and Singh, Vikrant and Veera, Viswanath and Venkatesan, Shankar M.},
title = {Photo-Realistic Emoticon Generation Using Multi-Modal Input},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377533},
doi = {10.1145/3377325.3377533},
abstract = {Emojis have changed the way humans communicate today. They are the most convenient non-linguistic social cues available to us in this era of social media. But there is no methodology wherein users can creatively interact with their systems to generate personalised emojis or edit existing ones. While there have been some experiments that enable networks to create images, there is no comprehensive solution that gives users the control to create personalised emoticons. In this work, we propose an end-to-end architecture to create a realistic emoji from a roughly drawn sketch. Our generated emojis show a PSNR value of 20.30dB and a SSIM of 0.914. Additionally, we look at a multi-modal architecture which generates an emoji when given an incomplete sketch along with a handwritten word describing the associated emotion.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {254â€“258},
numpages = {5},
keywords = {content generation, emoticon, multi-modal recognition},
location = {Cagliari, Italy},
series = {IUI '20}
}